{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75cd3990bcaaddd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb7764dfa1d007a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:20:06.656668100Z",
     "start_time": "2024-01-09T04:20:06.634689700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normal_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "data_dir = r'../data/crop/images/'\n",
    "dataset = datasets.ImageFolder(data_dir, transform=normal_transforms)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "validate_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - validate_size\n",
    "\n",
    "train_dataset, validate_dataset, test_dataset = random_split(dataset, [train_size, validate_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7390956683f337d0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'validate': validate_loader\n",
    "}\n",
    "dataset_sizes = {\n",
    "    'train': train_size,\n",
    "    'validate': validate_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "072a97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(data_dir):\n",
    "    all_data = datasets.ImageFolder(data_dir)\n",
    "    return all_data.classes\n",
    "\n",
    "classes = get_classes(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374f84ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(r'../model/demo_resnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae102bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label :  tensor([4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = r'../data/crop/images/Nanowires/L6_00256e4ab29cc0903c09269165f96443.jpg'\n",
    "image = Image.open(image_path)\n",
    "input_image = normal_transforms(image)\n",
    "input_image = input_image.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_image.cuda())\n",
    "\n",
    "_, predicted_label = torch.max(output, 1)\n",
    "\n",
    "print('label : ', predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19f95b871e60150",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[132   0   0   2   9   4   1   0   1   0]\n",
      " [  2   3   0   5   5   0   0   0   0   1]\n",
      " [  0   0  13   2   4  22   2   0   7   2]\n",
      " [  2   0   0 570   7   4  36   0   0  17]\n",
      " [  3   0   0  11 457  46   5   0   3  20]\n",
      " [  0   0   1   1   3 475   6   1   4   3]\n",
      " [  2   1   1  35  11  25 401   2   1  19]\n",
      " [  1   0   0   2   3   4   1  10   0   0]\n",
      " [  1   0   0   0  12  12   3   0 114   1]\n",
      " [  2   0   0   8   2   6  13   0   0 203]]\n",
      "Accuracy: 0.8529411764705882\n",
      "Precision: 0.8563285848867715\n",
      "Recall: 0.8529411764705882\n",
      "F1 Score: 0.8481356393827688\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
